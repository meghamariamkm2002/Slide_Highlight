Attend to What I Say: Highlighting Relevant Content on Slides

ðŸ“Œ Overview The goal of this project is to automatically highlight slide content that is relevant to a given spoken narration, enhancing understanding and accessibility for viewers. This is particularly useful in educational and conference presentation settings where slides and speech are tightly coupled.

This repository includes:

A curated dataset of slide frames aligned with audio and transcripts Code for different methods

Dataset The dataset consists of: Slide frames extracted from conference talks Speech transcripts (aligned to slides) Ground-truth highlight annotations marking slide regions relevant to each spoken segment

Details:

Format: Images (PNG), Transcripts (SRT), Annotations (JSON), Audio (MP3) Collected from various academic conferences (NeurIPS, ICML)

