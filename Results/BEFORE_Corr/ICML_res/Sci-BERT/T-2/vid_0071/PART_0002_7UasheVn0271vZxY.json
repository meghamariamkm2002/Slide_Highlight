{
    "MatchedRegions": [
        {
            "start_time": "00:00:01,323",
            "end_time": "00:00:06,766",
            "transcript": "Before diving into the main topic, let us understand concepts from the perspective of a DNN.",
            "MatchedRegion": [
                {
                    "Text": "Preliminaries: Understanding concepts encoded by a DNN",
                    "BoundingBox": {
                        "Width": 0.827545166015625,
                        "Height": 0.05766775459051132,
                        "Left": 0.09811194986104965,
                        "Top": 0.06659873574972153
                    },
                    "BlockType": "LAYOUT_TITLE",
                    "Id": "2de4ae58-f8e1-49b0-a464-0375adaa7861",
                    "Score": 0.8151772022247314
                },
                {
                    "Text": "Each concept represents an AND relationship between input variables, i.e., a concept is activated only when all variables in this concept exist (not masked).",
                    "BoundingBox": {
                        "Width": 0.6567968130111694,
                        "Height": 0.07813157141208649,
                        "Left": 0.18507501482963562,
                        "Top": 0.206549271941185
                    },
                    "BlockType": "LAYOUT_TEXT",
                    "Id": "508012c9-68ca-4a81-8603-d6b1aab7008b",
                    "Score": 0.7972137928009033
                },
                {
                    "Text": "Example in a vision task",
                    "BoundingBox": {
                        "Width": 0.1786850243806839,
                        "Height": 0.028927788138389587,
                        "Left": 0.1401623636484146,
                        "Top": 0.34072166681289673
                    },
                    "BlockType": "LAYOUT_SECTION_HEADER",
                    "Id": "15c38627-ed45-4e16-b1f1-d07be5f88d5b",
                    "Score": 0.7094794511795044
                },
                {
                    "Text": "input image activated concepts (semantic regions) (None)",
                    "BoundingBox": {
                        "Width": 0.4357546865940094,
                        "Height": 0.5529811382293701,
                        "Left": 0.04702353477478027,
                        "Top": 0.39411255717277527
                    },
                    "BlockType": "LAYOUT_FIGURE",
                    "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
                    "Score": 0.7177303433418274
                },
                {
                    "Text": "Example in an NLP task",
                    "BoundingBox": {
                        "Width": 0.1742016226053238,
                        "Height": 0.02887902967631817,
                        "Left": 0.6421084403991699,
                        "Top": 0.340349942445755
                    },
                    "BlockType": "LAYOUT_SECTION_HEADER",
                    "Id": "3e4e7032-ec2c-4cc1-9fd9-86dc24ea2e04",
                    "Score": 0.7102645039558411
                }
            ]
        },
        {
            "start_time": "00:00:07,807",
            "end_time": "00:00:14,650",
            "transcript": "Briefly speaking, each concept is activated when all pixels or words composing this concept exist.",
            "MatchedRegion": [
                {
                    "Text": "Each concept represents an AND relationship between input variables, i.e., a concept is activated only when all variables in this concept exist (not masked).",
                    "BoundingBox": {
                        "Width": 0.6567968130111694,
                        "Height": 0.07813157141208649,
                        "Left": 0.18507501482963562,
                        "Top": 0.206549271941185
                    },
                    "BlockType": "LAYOUT_TEXT",
                    "Id": "508012c9-68ca-4a81-8603-d6b1aab7008b",
                    "Score": 0.7972137928009033
                },
                {
                    "Text": "input image activated concepts (semantic regions) (None)",
                    "BoundingBox": {
                        "Width": 0.4357546865940094,
                        "Height": 0.5529811382293701,
                        "Left": 0.04702353477478027,
                        "Top": 0.39411255717277527
                    },
                    "BlockType": "LAYOUT_FIGURE",
                    "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
                    "Score": 0.7177303433418274
                }
            ]
        },
        {
            "start_time": "00:00:15,591",
            "end_time": "00:00:22,615",
            "transcript": "For example, when we feed a basket image or a basket sentence to the DNN, no concept will be activated.",
            "MatchedRegion": [
                {
                    "Text": "Each concept represents an AND relationship between input variables, i.e., a concept is activated only when all variables in this concept exist (not masked).",
                    "BoundingBox": {
                        "Width": 0.6567968130111694,
                        "Height": 0.07813157141208649,
                        "Left": 0.18507501482963562,
                        "Top": 0.206549271941185
                    },
                    "BlockType": "LAYOUT_TEXT",
                    "Id": "508012c9-68ca-4a81-8603-d6b1aab7008b",
                    "Score": 0.7972137928009033
                },
                {
                    "Text": "input image activated concepts (semantic regions) (None)",
                    "BoundingBox": {
                        "Width": 0.4357546865940094,
                        "Height": 0.5529811382293701,
                        "Left": 0.04702353477478027,
                        "Top": 0.39411255717277527
                    },
                    "BlockType": "LAYOUT_FIGURE",
                    "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
                    "Score": 0.7177303433418274
                }
            ]
        },
        {
            "start_time": "00:00:23,885",
            "end_time": "00:00:31,837",
            "transcript": "However, when less portion of the input sample is masked, as shown in these two examples, more concepts will emerge.",
            "MatchedRegion": [
                {
                    "Text": "Each concept represents an AND relationship between input variables, i.e., a concept is activated only when all variables in this concept exist (not masked).",
                    "BoundingBox": {
                        "Width": 0.6567968130111694,
                        "Height": 0.07813157141208649,
                        "Left": 0.18507501482963562,
                        "Top": 0.206549271941185
                    },
                    "BlockType": "LAYOUT_TEXT",
                    "Id": "508012c9-68ca-4a81-8603-d6b1aab7008b",
                    "Score": 0.7972137928009033
                },
                {
                    "Text": "Example in a vision task",
                    "BoundingBox": {
                        "Width": 0.1786850243806839,
                        "Height": 0.028927788138389587,
                        "Left": 0.1401623636484146,
                        "Top": 0.34072166681289673
                    },
                    "BlockType": "LAYOUT_SECTION_HEADER",
                    "Id": "15c38627-ed45-4e16-b1f1-d07be5f88d5b",
                    "Score": 0.7094794511795044
                },
                {
                    "Text": "input image activated concepts (semantic regions) (None)",
                    "BoundingBox": {
                        "Width": 0.4357546865940094,
                        "Height": 0.5529811382293701,
                        "Left": 0.04702353477478027,
                        "Top": 0.39411255717277527
                    },
                    "BlockType": "LAYOUT_FIGURE",
                    "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
                    "Score": 0.7177303433418274
                }
            ]
        }
    ]
}