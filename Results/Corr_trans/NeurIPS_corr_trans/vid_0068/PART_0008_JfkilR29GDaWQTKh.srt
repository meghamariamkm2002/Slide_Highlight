1
00:00:00,029 --> 00:00:00,630
which is used.

2
00:00:02,251 --> 00:00:09,919
We study if the predictor are good at estimating the end-to-end model accuracy after distillation and fine-tuning.

3
00:00:11,441 --> 00:00:12,422
There are three findings.

4
00:00:12,982 --> 00:00:22,953
One, distillation loss and linear regression used in donor is better than change of validation accuracy and simple summation used in NANDA.

5
00:00:24,276 --> 00:00:28,985
2.

6
00:00:24,717 --> 00:00:28,985
Symmetry of blocks that were distributed for more epoch tend to produce better predictors.

7
00:00:30,568 --> 00:00:35,918
The juice and predictor, which does not require any distillation signatures, can outperform

