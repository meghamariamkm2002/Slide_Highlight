1
00:00:01,033 --> 00:00:09,075
Unlike other methods, our method employs the losses during a short fine-tuning process on models that were already pre-trained on ImageNet.

2
00:00:10,016 --> 00:00:17,418
We add a classification loss (Lclassification) to ensure that the accuracy of the models does not decrease due to the fine-tuning process.

3
00:00:18,418 --> 00:00:24,800
The formulation of our classification loss is as follows, and it encourages the model to have high confidence on its predictions.

4
00:00:25,970 --> 00:00:32,154
Thus, our final loss term is formulated as follows as a combination of the relevance and the classification loss.

