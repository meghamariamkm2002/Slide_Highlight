1
00:00:01,570 --> 00:00:11,719
We noted in order to apply loss terms on the relevance of the foreground in the background, our method requires segmentation maps to distinguish between the background and the foreground of the input image.

2
00:00:12,659 --> 00:00:17,704
We use either human annotated maps or maps produced by DINO (without human supervision).

3
00:00:18,344 --> 00:00:21,307
Both cases lead to a similar improvement in robustness.

4
00:00:22,487 --> 00:00:27,812
Our method only uses three examples from half the images in classes during the fine-tuning process.

5
00:00:28,260 --> 00:00:31,599
meaning an overall of only 1500 training samples.

