To couple them, we employ the donscopardon form of the KL whose optimality point is precisely at the negative log distribution ratio.
Therefore, we can alternate between computing x through the donscopardon and using negative x as your reward in an RL algorithm.
This leads directly to our approach for estimating the longer ratio by coupling two flows through x, that is, instead of training two flows independently, we propose to do so by injecting the inductive bias seen in the slide.
This coupling guarantees more meaningful values when the flows are evaluated on each other's data, since it has already occurred during the maximization phase, hence side-stepping the ODE I should describe earlier.
The new BC graph illustrates this advantage.
Some additional components we find useful, whose motivation and details can be found in the paper, are a squasher on X, an optional flow regularization and smoothing.
Finally, combining all these elements is our algorithm, coupled flow imitation learning.
