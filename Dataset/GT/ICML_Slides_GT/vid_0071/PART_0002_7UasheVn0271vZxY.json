{
  "MatchedRegions": [
      {
          "start_time": "00:00:01,323",
          "end_time": "00:00:06,766",
          "transcript": "Before diving into the main topic, let us understand concepts from the perspective of a DNN.",
          "MatchedRegion": [
            {
              "Id": "2de4ae58-f8e1-49b0-a464-0375adaa7861",
              "Text": "Preliminaries: Understanding concepts encoded by a DNN",
              "BoundingBox": {
                  "Width": 0.827545166015625,
                  "Height": 0.05766775459051132,
                  "Left": 0.09811194986104965,
                  "Top": 0.06659873574972153
              },
              "BlockType": "LAYOUT_TITLE"
            }
          ]
      },
      {
        "start_time": "00:00:07,807",
        "end_time": "00:00:14,650",
        "transcript": "Briefly speaking, each concept is activated when all pixels or words composing this concept exist.",
        "MatchedRegion": [
          {
            "Id": "508012c9-68ca-4a81-8603-d6b1aab7008b",
            "Text": "Each concept represents an AND relationship between input variables, i.e., a concept is activated only when all variables in this concept exist (not masked).",
            "BoundingBox": {
                "Width": 0.6567968130111694,
                "Height": 0.07813157141208649,
                "Left": 0.18507501482963562,
                "Top": 0.206549271941185
            },
            "BlockType": "LAYOUT_TEXT"
          },
          {
            "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
            "Text": "input image activated concepts (semantic regions) (None)",
            "BoundingBox": {
                "Width": 0.4357546865940094,
                "Height": 0.5529811382293701,
                "Left": 0.04702353477478027,
                "Top": 0.39411255717277527
            },
            "BlockType": "LAYOUT_FIGURE"
          }
        ]
      },
      {
        "start_time": "00:00:15,591",
        "end_time": "00:00:22,615",
        "transcript": "For example, when we feed a basket image or a basket sentence to the DNN, no concept will be activated.",
        "MatchedRegion": [
          {
            "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
            "Text": "input image activated concepts (semantic regions) (None)",
            "BoundingBox": {
                "Width": 0.4357546865940094,
                "Height": 0.5529811382293701,
                "Left": 0.04702353477478027,
                "Top": 0.39411255717277527
            },
            "BlockType": "LAYOUT_FIGURE"
          }
        ]
      },
      {
        "start_time": "00:00:23,885",
        "end_time": "00:00:31,837",
        "transcript": "However, when less portion of the input sample is masked, as shown in these two examples, more concepts will emerge.",
        "MatchedRegion": [
          {
            "Id": "15c38627-ed45-4e16-b1f1-d07be5f88d5b",
            "Text": "Example in a vision task",
            "BoundingBox": {
                "Width": 0.1786850243806839,
                "Height": 0.028927788138389587,
                "Left": 0.1401623636484146,
                "Top": 0.34072166681289673
            },
            "BlockType": "LAYOUT_SECTION_HEADER"
          },
          {
            "Id": "3ef5a744-95d8-4f3c-9ff7-9af26cb7384b",
            "Text": "input image activated concepts (semantic regions) (None)",
            "BoundingBox": {
                "Width": 0.4357546865940094,
                "Height": 0.5529811382293701,
                "Left": 0.04702353477478027,
                "Top": 0.39411255717277527
            },
            "BlockType": "LAYOUT_FIGURE"
          }
        ]
      }
  ],
  "MatchedSlides": []
}